---
title: "Analyzing NYPD Complaints"
author: "Matt Vang and Xin Yi Li"
date: "6/24/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Overview
Since the start of the pandemic, we have seen an increase in protests against police brutality accross the United States. Organizations have succeeded in making their complaints data public, which enabled data analysts to investigate the phenomenon of "bad apples" within police departments (see this [article](https://github.com/msr-ds3/coursework/blob/master/week4/ft_police_complaints.pdf) for more). 
We will extend on this article and the data they used, to discover *a) the difference in treatment of different gender-race*, *b) if there is a racial bias in the NY Police Department*, *c) how the NYPD can reduce the number of complaints*, and lastly *d) an attempt to create a model out of the data*.

## About The Data
Data is provided by the [New York Civil Liberties Union](https://github.com/new-york-civil-liberties-union/NYPD-Misconduct-Complaint-Database-Updated) from 2007-2017. To get started, run the bash script in /newyork to download the data. Next, use the 02_load_newyork_complaints file to clean and load it into the correct format. We can now process the data further for analysis.

## Initial Setup

The necessary libraries we will need are *tidyverse*, *ggplot2* (included in the previous), and *scales*. Other libraries useful for further analysis and modeling can be *lubridate* and *modelr*. To load in the data, use the loading file located in the /newyork folder and then call *load('ny_complaints.RData')*. We will also filter the data to only accounts from start of 2007 to end of March 2021. All different allegations within a complaint to a single officer will be collapsed to a single allegation.


```{r settingup, include=FALSE}
# set up libraries and options
library(tidyverse)
library(ggplot2)
library(scales)
library(modelr)
library(lubridate)

theme_set(theme_bw())
options(repr.plot.width=4, repr.plot.height=3)

### read in new york data
load('ny_complaints.RData')
ny_complaints <- ny_complaints %>%
  filter(ReceivedDate >= "2007-01-01" & ReceivedDate <= "2021-04-01") %>%
  distinct(OfficerID, ComplaintID, .keep_all = TRUE)
```

## Finding the bad apples

### Reshape data to prepare for plotting

We need to extract the number of complaints per officer information from the original dataset.

```{r create new frame, warning=FALSE}
### allegations made to each officer (collapsed multiple allegations in one incident into only ONE allegation)
officers_complaints <- ny_complaints %>%
  filter(ReceivedDate >= "2007-01-01" & ReceivedDate < "2018-01-01") %>%
  group_by(OfficerID,ComplaintID,FirstName,LastName,CurrentRankLong) %>%
  summarise() %>% ungroup()

### total number of distinct allegations made to each officer
distinct_complaints <- officers_complaints %>% group_by(OfficerID) %>%
  summarise(num_complaints = n()) %>% ungroup() %>%
  mutate(decile = ntile(num_complaints,10))
```

### Plotting

Replicating the article's graph. The top 10 percent of police officers are responsible for over 30 percent of all complaints.

```{r plot data, warning=FALSE}
distinct_complaints %>%
  group_by(decile) %>%
  summarise(total_complaints = sum(num_complaints)) %>%
  mutate(percent_of_total = total_complaints/sum(total_complaints)) %>%
  ggplot(aes(x=decile,y=percent_of_total)) + geom_histogram(stat = 'identity') +
  ylab("Proportion of complaints") + xlab("Decile")
```

## Difference In Treatment of Gender/Race

```{r gender-race, fig.align='center'}

### compare ratio of complaints vs. different & same gender
gender_differences_wm <- ny_complaints %>%
  filter(ImpactedGender != "", OfficerGender != "") %>%
  count(ImpactedGender, OfficerGender)

gender_differences_wm %>%
  ggplot(aes(x = ImpactedGender, y = n, fill = OfficerGender)) +
  geom_bar(position = position_dodge(), stat='identity') +
  scale_y_continuous() +
  xlab('Complainant Gender') +
  ylab('Number of complaints') +
  labs(fill='Officer\'s Gender', title='Gender Difference In Complainants and Officers')

#############################################################

### compare ratios betw gender & race, with focus on women & men

race_and_gender <- ny_complaints %>% filter(ImpactedGender != "", ImpactedRace != "") %>% count(ImpactedGender, ImpactedRace)

race_and_gender %>%
  group_by(ImpactedRace, ImpactedGender) %>%
  filter(ImpactedGender %in% c("Female", "Male")) %>%
  ggplot(aes(x = ImpactedRace, y = n)) +
  geom_bar(stat='identity') +
  facet_wrap(~ ImpactedGender) +
  xlab('Complainant Race') +
  ylab('Number of complaints') +
  labs(title='Cross Gender-Race Difference In Complainants and Officers')
```

There seems to be a huge gap between genders with sufficient data (Male and Female), where male complainants are more likely to be mishandled by male police officers. This could be because of an imbalance in the number of male police officers vs female.

## Investigating a racial bias phenomenon
In order to do this, we want to look at how the number of complaints differ across the impacted racial categories.

```{r racial bias, fig.align='center'}
## compare number of complaints differing by race
racial_differences <- ny_complaints %>%
  filter(ImpactedRace != "", OfficerRace != "") %>%
  count(ImpactedRace,OfficerRace)

racial_differences %>% mutate(percent = n/sum(n)) %>%
  ggplot(aes(x=reorder(ImpactedRace,percent), y = percent)) +
  geom_bar(aes(fill=OfficerRace),stat='identity') +
  scale_y_continuous(labels = percent_format(accuracy = 1))+
  labs(fill = "Officer\'s Race", title = 'Percent of Complaints Generated by Each Racial Group of Complainants')+
  xlab('Complainant\'s Race') +
  ylab('Percentage of total complaints') 

```

From the plot, we observe about 50% of the total complaints are from Black complainants, 22% from Hispanic complainants, 12% from White complainants, and less than 10% for other categories. This suggests a strong racial bias against Black people. In addition, across all categories, white officers account for a much higher percentage of the number of complaints. However, we are not able to determine that white officers are more likely to cause a complaint, as we do not have the full demographics data of the NYPD that accounts for all the officers who have never received a complaint.

On the other hand, we can investigate if the racial bias against black people occur differently across all groups of police officers who have received a complaint.

```{r racial bias accross police, fig.align='center'}
racial_differences %>%
  group_by(OfficerRace,ImpactedRace) %>%
  summarise(total_complaints = sum(n)) %>%
  ungroup() %>%
  group_by(OfficerRace) %>%
  mutate(total_complaints_percentage = total_complaints/sum(total_complaints)) %>%
  ggplot(aes(x=reorder(ImpactedRace,total_complaints_percentage),y=total_complaints_percentage)) +
  geom_bar(aes(fill = as.factor(ImpactedRace)),stat='identity') +
  scale_y_continuous(labels = percent_format(accuracy = 1))+
  facet_wrap(~ OfficerRace) +
  labs(fill="Impacted Race",title ='Complaints Ratio of Different Impacted Race Separated by The Officers\' Race' ) +
  xlab('Person Impacted\'s Race') +
  ylab('Ratio of Complaints') +
  theme(axis.text.x = element_blank())
```

Surprisingly, it seems like there isn't much variance. This indicates that the department as a whole, and not just any single group, has a serious racial bias issue that needs to be worked on. So, our next question would be what should they do to improve their performance and reduce the number of complaints?

## Possible improvements
To answer this question, we need to identify the areas where police officers tend to make mistakes at which period of time in their career.

First, we look at what types of allegations are officers more likely to be in trouble with.

```{r FADOtypes, fig.align='center'}
## FADO types complaints
ny_complaints %>% 
  count(FADOType) %>%
  mutate(percent = n/sum(n)) %>%
  group_by(FADOType) %>%
  ggplot(aes(x=FADOType,y=percent)) +
  geom_bar(stat='identity') +
  scale_y_continuous(labels = percent_format(accuracy = 1))+
  labs(title='Allegation Types') +
  xlab("Types of allegation") +
  ylab("Number of complaints")

```


The results show that Abuse Of Authority accounts for more than 40% of all allegations and Force accounts for roughly 35%. This is alarming as these allegations are much worse than others as they might have caused physical harms against the complainants or the complainants' properties.

We want to also investigate whether the number of complaints received increase or decrease the longer police officers are in the force. This is different from looking at each officer's total number of complaints at their recorded days on force. But rather, we are trying to figure out the number of complaints that occur within each group of police officers that have the same amount of experience (characterized by the days on force variable). For the sake of not over counting retired officers, we will only consider the ones who are still active as of April 1st, 2021.

```{r daysonforce, fig.align='center'}
### Days On Force differences
dof_differences <- ny_complaints %>%
  filter(DaysOnForce>0, LastActive == '4/1/2021')

dof_differences %>%
  group_by(DaysOnForce) %>%
  ggplot() +
  geom_histogram(aes(x=DaysOnForce/365)) +
  xlab('Years Of Experience') +
  ylab('Number Of Complaints Occured') +
  labs(title = 'Generated Number of Complaints by Officers in Each Group of Equivalent Experience')

```

As we might have considered, the longer officers are in the force, the less likely they are to make mistakes that cause complaints. The most 'high risk' group is when officers have been in the force for about 2-6 years.

From this information as long as with the most frequent allegations, we can come up with some suggestions that can be made to the NYPD. First, there needs to be a more strict protocol of when they should use force and power to apprehend a person. Second, racial bias needs to be taken seriously and dealt with. An idea could be encouraging officers to interact with minority groups through fundraising, charity events, or even counseling sessions to reduce their stress while on the job. Third, the department needs to provide better training to their new recruits. A system of partnering or mentoring between an experienced officer with a less experienced one could be established.

One might also wonder how long does the complaint process take? We can see that information below.

```{r closingcomplaints, fig.align='center'}
## Look at how long it takes to close the complaints
days_of_complaints <- ny_complaints %>% mutate(days_to_close = CloseDate-ReceivedDate) %>% 
  filter(ReceivedDate >= "2007-01-01" & ReceivedDate < "2018-01-01") %>%
  group_by(OfficerID,ComplaintID,days_to_close) %>%
  summarise() %>% ungroup()

## plot - most of the time it takes 3 months - over 1 year
days_of_complaints %>% filter(days_to_close <= 700) %>%
  ggplot() +
  geom_histogram(aes(abs(x=days_to_close/30))) +
  scale_x_continuous(breaks=pretty_breaks(n=10)) +
  xlab('Months To Close') +
  ylab('Complaints') +
  labs(title='Amount of Time to Close A Complaint')
```

Data shows that it takes an incredibly long time for the complaints to be investigated and closed. Most ranging from 2 months to 8 months, while the majority sits around 3 months. A lot of the complaints have to wait for over a year to be closed. This systems needs much improvement as we need to hold officers accountable as soon as possible if they did violate the law against civilians.

## An Attempt to Predict The Number Of Accumulated Complaints Over Time (based on officer's identity and their first incident)
 
We will try to fit a model using multivariate multiple linear regression. The variables are: the officer's race and gender, their number of days on the job (experience),their first incident precint, and their first complaint allegation type. 

```{r modeling}
officers_first_incidents <- ny_complaints %>% 
  select(OfficerID,OfficerGender,OfficerRace,DaysOnForce,FADOType,IncidentPrecinct) %>%
  filter(DaysOnForce>0 & IncidentPrecinct != "") %>%
  group_by(OfficerID) %>%
  mutate(first_incident_FADO = first(FADOType), first_precint = first(IncidentPrecinct)) %>%
  ungroup() %>%
  group_by(OfficerID,OfficerGender,OfficerRace,DaysOnForce,first_incident_FADO,first_precint) %>%
  summarise(count=n()) %>% ungroup() %>%
  group_by(OfficerID) %>%
  mutate(accumulated_offenses = cumsum(count))
  
### Setting up training,testing, and validating sets
frac_train = 0.8
frac_test = 0.1

set.seed(2734)

num_observations <- nrow(officers_first_incidents)
frac_train <- 0.8
num_train <- floor(num_observations * frac_train)

# randomly sample rows for the training set 
train <- sample(1:num_observations, num_train, replace=F)

# training set used to fit the model
train_repeating_complaints <- officers_first_incidents[train, ]

# validate and test sets used to evaluate the fit
test_validate_set <- officers_first_incidents[-train, ]
num_test_validate <- floor((num_observations - num_train)/2)
validate <- sample(nrow(test_validate_set),num_test_validate,replace = F)

# validate and test
validate_repeating_complaints <- test_validate_set[validate,]
test_repeating_complaints <- test_validate_set[-validate,]

# training model
K <- 1:8
train_err <- c()
validate_err <- c()
for (k in K) {
  
  # fit on the training data
  model <- lm(accumulated_offenses ~ OfficerGender + OfficerRace +
         poly(DaysOnForce,k,raw=T) +
         first_precint +
         first_incident_FADO, data=train_repeating_complaints)
  
  # evaluate on the training data
  train_err[k] <- sqrt(mean((predict(model, train_repeating_complaints) - train_repeating_complaints$accumulated_offenses)^2))
  
  # evaluate on the validate data
  validate_err[k] <- sqrt(mean((predict(model, validate_repeating_complaints) - validate_repeating_complaints$accumulated_offenses)^2))
}

## Look at effects of polynomial degree
plot_data <- data.frame(K, train_err, validate_err) %>%
  gather("split", "error", -K)

ggplot(plot_data, aes(x=K, y=error, color=split)) +
  geom_line() +
  scale_x_continuous(breaks=K) +
  xlab('Polynomial Degree') +
  ylab('RMSE')

train_err
validate_err

## Final model to predict 
final_model <- lm(accumulated_offenses ~ OfficerGender + OfficerRace +
              poly(DaysOnForce,6,raw=T) +
              first_precint +
              first_incident_FADO, data=train_repeating_complaints)

## Testing error rate of about 2.53 number of accumulated complaints
test_err <- sqrt(mean((predict(model, test_repeating_complaints) - test_repeating_complaints$accumulated_offenses)^2))
test_err

```

The results are: 2.50 for training error, 2.47 for validating error, and about 2.53 for testing error (these numbers are the mean squared error of our predictions compared to actual values).

